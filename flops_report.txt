/Users/muradgamzatov/anaconda3/bin/python /Users/muradgamzatov/Desktop/mlops/models/torch2onnx.py
/Users/muradgamzatov/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  torch.utils._pytree._register_pytree_node(
/Users/muradgamzatov/anaconda3/lib/python3.11/site-packages/onnxscript/converter.py:820: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.
  param_schemas = callee.param_schemas()
/Users/muradgamzatov/anaconda3/lib/python3.11/site-packages/onnxscript/converter.py:820: FutureWarning: 'onnxscript.values.OnnxFunction.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.
  param_schemas = callee.param_schemas()
Unsupported operator aten::embedding encountered 2 time(s)
Unsupported operator aten::rsub encountered 1 time(s)
Unsupported operator aten::mul encountered 53 time(s)
Unsupported operator aten::pow encountered 25 time(s)
Unsupported operator aten::mean encountered 25 time(s)
Unsupported operator aten::add encountered 52 time(s)
Unsupported operator aten::rsqrt encountered 25 time(s)
Unsupported operator aten::sub encountered 1 time(s)
Unsupported operator aten::abs encountered 1 time(s)
Unsupported operator aten::lt encountered 1 time(s)
Unsupported operator aten::div encountered 2 time(s)
Unsupported operator aten::log encountered 1 time(s)
Unsupported operator aten::min encountered 1 time(s)
Unsupported operator aten::where encountered 1 time(s)
Unsupported operator aten::add_ encountered 13 time(s)
Unsupported operator aten::softmax encountered 12 time(s)
The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
transformer.decoder, transformer.decoder.block.0, transformer.decoder.block.0.layer.0, transformer.decoder.block.0.layer.0.SelfAttention, transformer.decoder.block.0.layer.0.SelfAttention.k, transformer.decoder.block.0.layer.0.SelfAttention.o, transformer.decoder.block.0.layer.0.SelfAttention.q, transformer.decoder.block.0.layer.0.SelfAttention.relative_attention_bias, transformer.decoder.block.0.layer.0.SelfAttention.v, transformer.decoder.block.0.layer.0.dropout, transformer.decoder.block.0.layer.0.layer_norm, transformer.decoder.block.0.layer.1, transformer.decoder.block.0.layer.1.EncDecAttention, transformer.decoder.block.0.layer.1.EncDecAttention.k, transformer.decoder.block.0.layer.1.EncDecAttention.o, transformer.decoder.block.0.layer.1.EncDecAttention.q, transformer.decoder.block.0.layer.1.EncDecAttention.v, transformer.decoder.block.0.layer.1.dropout, transformer.decoder.block.0.layer.1.layer_norm, transformer.decoder.block.0.layer.2, transformer.decoder.block.0.layer.2.DenseReluDense, transformer.decoder.block.0.layer.2.DenseReluDense.act, transformer.decoder.block.0.layer.2.DenseReluDense.dropout, transformer.decoder.block.0.layer.2.DenseReluDense.wi, transformer.decoder.block.0.layer.2.DenseReluDense.wo, transformer.decoder.block.0.layer.2.dropout, transformer.decoder.block.0.layer.2.layer_norm, transformer.decoder.block.1, transformer.decoder.block.1.layer.0, transformer.decoder.block.1.layer.0.SelfAttention, transformer.decoder.block.1.layer.0.SelfAttention.k, transformer.decoder.block.1.layer.0.SelfAttention.o, transformer.decoder.block.1.layer.0.SelfAttention.q, transformer.decoder.block.1.layer.0.SelfAttention.v, transformer.decoder.block.1.layer.0.dropout, transformer.decoder.block.1.layer.0.layer_norm, transformer.decoder.block.1.layer.1, transformer.decoder.block.1.layer.1.EncDecAttention, transformer.decoder.block.1.layer.1.EncDecAttention.k, transformer.decoder.block.1.layer.1.EncDecAttention.o, transformer.decoder.block.1.layer.1.EncDecAttention.q, transformer.decoder.block.1.layer.1.EncDecAttention.v, transformer.decoder.block.1.layer.1.dropout, transformer.decoder.block.1.layer.1.layer_norm, transformer.decoder.block.1.layer.2, transformer.decoder.block.1.layer.2.DenseReluDense, transformer.decoder.block.1.layer.2.DenseReluDense.act, transformer.decoder.block.1.layer.2.DenseReluDense.dropout, transformer.decoder.block.1.layer.2.DenseReluDense.wi, transformer.decoder.block.1.layer.2.DenseReluDense.wo, transformer.decoder.block.1.layer.2.dropout, transformer.decoder.block.1.layer.2.layer_norm, transformer.decoder.block.10, transformer.decoder.block.10.layer.0, transformer.decoder.block.10.layer.0.SelfAttention, transformer.decoder.block.10.layer.0.SelfAttention.k, transformer.decoder.block.10.layer.0.SelfAttention.o, transformer.decoder.block.10.layer.0.SelfAttention.q, transformer.decoder.block.10.layer.0.SelfAttention.v, transformer.decoder.block.10.layer.0.dropout, transformer.decoder.block.10.layer.0.layer_norm, transformer.decoder.block.10.layer.1, transformer.decoder.block.10.layer.1.EncDecAttention, transformer.decoder.block.10.layer.1.EncDecAttention.k, transformer.decoder.block.10.layer.1.EncDecAttention.o, transformer.decoder.block.10.layer.1.EncDecAttention.q, transformer.decoder.block.10.layer.1.EncDecAttention.v, transformer.decoder.block.10.layer.1.dropout, transformer.decoder.block.10.layer.1.layer_norm, transformer.decoder.block.10.layer.2, transformer.decoder.block.10.layer.2.DenseReluDense, transformer.decoder.block.10.layer.2.DenseReluDense.act, transformer.decoder.block.10.layer.2.DenseReluDense.dropout, transformer.decoder.block.10.layer.2.DenseReluDense.wi, transformer.decoder.block.10.layer.2.DenseReluDense.wo, transformer.decoder.block.10.layer.2.dropout, transformer.decoder.block.10.layer.2.layer_norm, transformer.decoder.block.11, transformer.decoder.block.11.layer.0, transformer.decoder.block.11.layer.0.SelfAttention, transformer.decoder.block.11.layer.0.SelfAttention.k, transformer.decoder.block.11.layer.0.SelfAttention.o, transformer.decoder.block.11.layer.0.SelfAttention.q, transformer.decoder.block.11.layer.0.SelfAttention.v, transformer.decoder.block.11.layer.0.dropout, transformer.decoder.block.11.layer.0.layer_norm, transformer.decoder.block.11.layer.1, transformer.decoder.block.11.layer.1.EncDecAttention, transformer.decoder.block.11.layer.1.EncDecAttention.k, transformer.decoder.block.11.layer.1.EncDecAttention.o, transformer.decoder.block.11.layer.1.EncDecAttention.q, transformer.decoder.block.11.layer.1.EncDecAttention.v, transformer.decoder.block.11.layer.1.dropout, transformer.decoder.block.11.layer.1.layer_norm, transformer.decoder.block.11.layer.2, transformer.decoder.block.11.layer.2.DenseReluDense, transformer.decoder.block.11.layer.2.DenseReluDense.act, transformer.decoder.block.11.layer.2.DenseReluDense.dropout, transformer.decoder.block.11.layer.2.DenseReluDense.wi, transformer.decoder.block.11.layer.2.DenseReluDense.wo, transformer.decoder.block.11.layer.2.dropout, transformer.decoder.block.11.layer.2.layer_norm, transformer.decoder.block.2, transformer.decoder.block.2.layer.0, transformer.decoder.block.2.layer.0.SelfAttention, transformer.decoder.block.2.layer.0.SelfAttention.k, transformer.decoder.block.2.layer.0.SelfAttention.o, transformer.decoder.block.2.layer.0.SelfAttention.q, transformer.decoder.block.2.layer.0.SelfAttention.v, transformer.decoder.block.2.layer.0.dropout, transformer.decoder.block.2.layer.0.layer_norm, transformer.decoder.block.2.layer.1, transformer.decoder.block.2.layer.1.EncDecAttention, transformer.decoder.block.2.layer.1.EncDecAttention.k, transformer.decoder.block.2.layer.1.EncDecAttention.o, transformer.decoder.block.2.layer.1.EncDecAttention.q, transformer.decoder.block.2.layer.1.EncDecAttention.v, transformer.decoder.block.2.layer.1.dropout, transformer.decoder.block.2.layer.1.layer_norm, transformer.decoder.block.2.layer.2, transformer.decoder.block.2.layer.2.DenseReluDense, transformer.decoder.block.2.layer.2.DenseReluDense.act, transformer.decoder.block.2.layer.2.DenseReluDense.dropout, transformer.decoder.block.2.layer.2.DenseReluDense.wi, transformer.decoder.block.2.layer.2.DenseReluDense.wo, transformer.decoder.block.2.layer.2.dropout, transformer.decoder.block.2.layer.2.layer_norm, transformer.decoder.block.3, transformer.decoder.block.3.layer.0, transformer.decoder.block.3.layer.0.SelfAttention, transformer.decoder.block.3.layer.0.SelfAttention.k, transformer.decoder.block.3.layer.0.SelfAttention.o, transformer.decoder.block.3.layer.0.SelfAttention.q, transformer.decoder.block.3.layer.0.SelfAttention.v, transformer.decoder.block.3.layer.0.dropout, transformer.decoder.block.3.layer.0.layer_norm, transformer.decoder.block.3.layer.1, transformer.decoder.block.3.layer.1.EncDecAttention, transformer.decoder.block.3.layer.1.EncDecAttention.k, transformer.decoder.block.3.layer.1.EncDecAttention.o, transformer.decoder.block.3.layer.1.EncDecAttention.q, transformer.decoder.block.3.layer.1.EncDecAttention.v, transformer.decoder.block.3.layer.1.dropout, transformer.decoder.block.3.layer.1.layer_norm, transformer.decoder.block.3.layer.2, transformer.decoder.block.3.layer.2.DenseReluDense, transformer.decoder.block.3.layer.2.DenseReluDense.act, transformer.decoder.block.3.layer.2.DenseReluDense.dropout, transformer.decoder.block.3.layer.2.DenseReluDense.wi, transformer.decoder.block.3.layer.2.DenseReluDense.wo, transformer.decoder.block.3.layer.2.dropout, transformer.decoder.block.3.layer.2.layer_norm, transformer.decoder.block.4, transformer.decoder.block.4.layer.0, transformer.decoder.block.4.layer.0.SelfAttention, transformer.decoder.block.4.layer.0.SelfAttention.k, transformer.decoder.block.4.layer.0.SelfAttention.o, transformer.decoder.block.4.layer.0.SelfAttention.q, transformer.decoder.block.4.layer.0.SelfAttention.v, transformer.decoder.block.4.layer.0.dropout, transformer.decoder.block.4.layer.0.layer_norm, transformer.decoder.block.4.layer.1, transformer.decoder.block.4.layer.1.EncDecAttention, transformer.decoder.block.4.layer.1.EncDecAttention.k, transformer.decoder.block.4.layer.1.EncDecAttention.o, transformer.decoder.block.4.layer.1.EncDecAttention.q, transformer.decoder.block.4.layer.1.EncDecAttention.v, transformer.decoder.block.4.layer.1.dropout, transformer.decoder.block.4.layer.1.layer_norm, transformer.decoder.block.4.layer.2, transformer.decoder.block.4.layer.2.DenseReluDense, transformer.decoder.block.4.layer.2.DenseReluDense.act, transformer.decoder.block.4.layer.2.DenseReluDense.dropout, transformer.decoder.block.4.layer.2.DenseReluDense.wi, transformer.decoder.block.4.layer.2.DenseReluDense.wo, transformer.decoder.block.4.layer.2.dropout, transformer.decoder.block.4.layer.2.layer_norm, transformer.decoder.block.5, transformer.decoder.block.5.layer.0, transformer.decoder.block.5.layer.0.SelfAttention, transformer.decoder.block.5.layer.0.SelfAttention.k, transformer.decoder.block.5.layer.0.SelfAttention.o, transformer.decoder.block.5.layer.0.SelfAttention.q, transformer.decoder.block.5.layer.0.SelfAttention.v, transformer.decoder.block.5.layer.0.dropout, transformer.decoder.block.5.layer.0.layer_norm, transformer.decoder.block.5.layer.1, transformer.decoder.block.5.layer.1.EncDecAttention, transformer.decoder.block.5.layer.1.EncDecAttention.k, transformer.decoder.block.5.layer.1.EncDecAttention.o, transformer.decoder.block.5.layer.1.EncDecAttention.q, transformer.decoder.block.5.layer.1.EncDecAttention.v, transformer.decoder.block.5.layer.1.dropout, transformer.decoder.block.5.layer.1.layer_norm, transformer.decoder.block.5.layer.2, transformer.decoder.block.5.layer.2.DenseReluDense, transformer.decoder.block.5.layer.2.DenseReluDense.act, transformer.decoder.block.5.layer.2.DenseReluDense.dropout, transformer.decoder.block.5.layer.2.DenseReluDense.wi, transformer.decoder.block.5.layer.2.DenseReluDense.wo, transformer.decoder.block.5.layer.2.dropout, transformer.decoder.block.5.layer.2.layer_norm, transformer.decoder.block.6, transformer.decoder.block.6.layer.0, transformer.decoder.block.6.layer.0.SelfAttention, transformer.decoder.block.6.layer.0.SelfAttention.k, transformer.decoder.block.6.layer.0.SelfAttention.o, transformer.decoder.block.6.layer.0.SelfAttention.q, transformer.decoder.block.6.layer.0.SelfAttention.v, transformer.decoder.block.6.layer.0.dropout, transformer.decoder.block.6.layer.0.layer_norm, transformer.decoder.block.6.layer.1, transformer.decoder.block.6.layer.1.EncDecAttention, transformer.decoder.block.6.layer.1.EncDecAttention.k, transformer.decoder.block.6.layer.1.EncDecAttention.o, transformer.decoder.block.6.layer.1.EncDecAttention.q, transformer.decoder.block.6.layer.1.EncDecAttention.v, transformer.decoder.block.6.layer.1.dropout, transformer.decoder.block.6.layer.1.layer_norm, transformer.decoder.block.6.layer.2, transformer.decoder.block.6.layer.2.DenseReluDense, transformer.decoder.block.6.layer.2.DenseReluDense.act, transformer.decoder.block.6.layer.2.DenseReluDense.dropout, transformer.decoder.block.6.layer.2.DenseReluDense.wi, transformer.decoder.block.6.layer.2.DenseReluDense.wo, transformer.decoder.block.6.layer.2.dropout, transformer.decoder.block.6.layer.2.layer_norm, transformer.decoder.block.7, transformer.decoder.block.7.layer.0, transformer.decoder.block.7.layer.0.SelfAttention, transformer.decoder.block.7.layer.0.SelfAttention.k, transformer.decoder.block.7.layer.0.SelfAttention.o, transformer.decoder.block.7.layer.0.SelfAttention.q, transformer.decoder.block.7.layer.0.SelfAttention.v, transformer.decoder.block.7.layer.0.dropout, transformer.decoder.block.7.layer.0.layer_norm, transformer.decoder.block.7.layer.1, transformer.decoder.block.7.layer.1.EncDecAttention, transformer.decoder.block.7.layer.1.EncDecAttention.k, transformer.decoder.block.7.layer.1.EncDecAttention.o, transformer.decoder.block.7.layer.1.EncDecAttention.q, transformer.decoder.block.7.layer.1.EncDecAttention.v, transformer.decoder.block.7.layer.1.dropout, transformer.decoder.block.7.layer.1.layer_norm, transformer.decoder.block.7.layer.2, transformer.decoder.block.7.layer.2.DenseReluDense, transformer.decoder.block.7.layer.2.DenseReluDense.act, transformer.decoder.block.7.layer.2.DenseReluDense.dropout, transformer.decoder.block.7.layer.2.DenseReluDense.wi, transformer.decoder.block.7.layer.2.DenseReluDense.wo, transformer.decoder.block.7.layer.2.dropout, transformer.decoder.block.7.layer.2.layer_norm, transformer.decoder.block.8, transformer.decoder.block.8.layer.0, transformer.decoder.block.8.layer.0.SelfAttention, transformer.decoder.block.8.layer.0.SelfAttention.k, transformer.decoder.block.8.layer.0.SelfAttention.o, transformer.decoder.block.8.layer.0.SelfAttention.q, transformer.decoder.block.8.layer.0.SelfAttention.v, transformer.decoder.block.8.layer.0.dropout, transformer.decoder.block.8.layer.0.layer_norm, transformer.decoder.block.8.layer.1, transformer.decoder.block.8.layer.1.EncDecAttention, transformer.decoder.block.8.layer.1.EncDecAttention.k, transformer.decoder.block.8.layer.1.EncDecAttention.o, transformer.decoder.block.8.layer.1.EncDecAttention.q, transformer.decoder.block.8.layer.1.EncDecAttention.v, transformer.decoder.block.8.layer.1.dropout, transformer.decoder.block.8.layer.1.layer_norm, transformer.decoder.block.8.layer.2, transformer.decoder.block.8.layer.2.DenseReluDense, transformer.decoder.block.8.layer.2.DenseReluDense.act, transformer.decoder.block.8.layer.2.DenseReluDense.dropout, transformer.decoder.block.8.layer.2.DenseReluDense.wi, transformer.decoder.block.8.layer.2.DenseReluDense.wo, transformer.decoder.block.8.layer.2.dropout, transformer.decoder.block.8.layer.2.layer_norm, transformer.decoder.block.9, transformer.decoder.block.9.layer.0, transformer.decoder.block.9.layer.0.SelfAttention, transformer.decoder.block.9.layer.0.SelfAttention.k, transformer.decoder.block.9.layer.0.SelfAttention.o, transformer.decoder.block.9.layer.0.SelfAttention.q, transformer.decoder.block.9.layer.0.SelfAttention.v, transformer.decoder.block.9.layer.0.dropout, transformer.decoder.block.9.layer.0.layer_norm, transformer.decoder.block.9.layer.1, transformer.decoder.block.9.layer.1.EncDecAttention, transformer.decoder.block.9.layer.1.EncDecAttention.k, transformer.decoder.block.9.layer.1.EncDecAttention.o, transformer.decoder.block.9.layer.1.EncDecAttention.q, transformer.decoder.block.9.layer.1.EncDecAttention.v, transformer.decoder.block.9.layer.1.dropout, transformer.decoder.block.9.layer.1.layer_norm, transformer.decoder.block.9.layer.2, transformer.decoder.block.9.layer.2.DenseReluDense, transformer.decoder.block.9.layer.2.DenseReluDense.act, transformer.decoder.block.9.layer.2.DenseReluDense.dropout, transformer.decoder.block.9.layer.2.DenseReluDense.wi, transformer.decoder.block.9.layer.2.DenseReluDense.wo, transformer.decoder.block.9.layer.2.dropout, transformer.decoder.block.9.layer.2.layer_norm, transformer.decoder.dropout, transformer.decoder.final_layer_norm
Суммарное количество FLOPs: 2729705472

FLOPs по слоям:
: 2729705472
transformer: 2727346176
transformer.shared: 0
transformer.encoder: 2727346176
transformer.encoder.block: 2727346176
transformer.encoder.block.0: 227278848
transformer.encoder.block.0.layer: 227278848
transformer.encoder.block.0.layer.0: 76283904
transformer.encoder.block.0.layer.0.SelfAttention: 76283904
transformer.encoder.block.0.layer.0.SelfAttention.q: 18874368
transformer.encoder.block.0.layer.0.SelfAttention.k: 18874368
transformer.encoder.block.0.layer.0.SelfAttention.v: 18874368
transformer.encoder.block.0.layer.0.SelfAttention.o: 18874368
transformer.encoder.block.0.layer.0.SelfAttention.relative_attention_bias: 0
transformer.encoder.block.0.layer.0.layer_norm: 0
transformer.encoder.block.0.layer.0.dropout: 0
transformer.encoder.block.0.layer.1: 150994944
transformer.encoder.block.0.layer.1.DenseReluDense: 150994944
transformer.encoder.block.0.layer.1.DenseReluDense.wi: 75497472
transformer.encoder.block.0.layer.1.DenseReluDense.wo: 75497472
transformer.encoder.block.0.layer.1.DenseReluDense.dropout: 0
transformer.encoder.block.0.layer.1.DenseReluDense.act: 0
transformer.encoder.block.0.layer.1.layer_norm: 0
transformer.encoder.block.0.layer.1.dropout: 0
transformer.encoder.block.1: 227278848
transformer.encoder.block.1.layer: 227278848
transformer.encoder.block.1.layer.0: 76283904
transformer.encoder.block.1.layer.0.SelfAttention: 76283904
transformer.encoder.block.1.layer.0.SelfAttention.q: 18874368
transformer.encoder.block.1.layer.0.SelfAttention.k: 18874368
transformer.encoder.block.1.layer.0.SelfAttention.v: 18874368
transformer.encoder.block.1.layer.0.SelfAttention.o: 18874368
transformer.encoder.block.1.layer.0.layer_norm: 0
transformer.encoder.block.1.layer.0.dropout: 0
transformer.encoder.block.1.layer.1: 150994944
transformer.encoder.block.1.layer.1.DenseReluDense: 150994944
transformer.encoder.block.1.layer.1.DenseReluDense.wi: 75497472
transformer.encoder.block.1.layer.1.DenseReluDense.wo: 75497472
transformer.encoder.block.1.layer.1.DenseReluDense.dropout: 0
transformer.encoder.block.1.layer.1.DenseReluDense.act: 0
transformer.encoder.block.1.layer.1.layer_norm: 0
transformer.encoder.block.1.layer.1.dropout: 0
transformer.encoder.block.2: 227278848
transformer.encoder.block.2.layer: 227278848
transformer.encoder.block.2.layer.0: 76283904
transformer.encoder.block.2.layer.0.SelfAttention: 76283904
transformer.encoder.block.2.layer.0.SelfAttention.q: 18874368
transformer.encoder.block.2.layer.0.SelfAttention.k: 18874368
transformer.encoder.block.2.layer.0.SelfAttention.v: 18874368
transformer.encoder.block.2.layer.0.SelfAttention.o: 18874368
transformer.encoder.block.2.layer.0.layer_norm: 0
transformer.encoder.block.2.layer.0.dropout: 0
transformer.encoder.block.2.layer.1: 150994944
transformer.encoder.block.2.layer.1.DenseReluDense: 150994944
transformer.encoder.block.2.layer.1.DenseReluDense.wi: 75497472
transformer.encoder.block.2.layer.1.DenseReluDense.wo: 75497472
transformer.encoder.block.2.layer.1.DenseReluDense.dropout: 0
transformer.encoder.block.2.layer.1.DenseReluDense.act: 0
transformer.encoder.block.2.layer.1.layer_norm: 0
transformer.encoder.block.2.layer.1.dropout: 0
transformer.encoder.block.3: 227278848
transformer.encoder.block.3.layer: 227278848
transformer.encoder.block.3.layer.0: 76283904
transformer.encoder.block.3.layer.0.SelfAttention: 76283904
transformer.encoder.block.3.layer.0.SelfAttention.q: 18874368
transformer.encoder.block.3.layer.0.SelfAttention.k: 18874368
transformer.encoder.block.3.layer.0.SelfAttention.v: 18874368
transformer.encoder.block.3.layer.0.SelfAttention.o: 18874368
transformer.encoder.block.3.layer.0.layer_norm: 0
transformer.encoder.block.3.layer.0.dropout: 0
transformer.encoder.block.3.layer.1: 150994944
transformer.encoder.block.3.layer.1.DenseReluDense: 150994944
transformer.encoder.block.3.layer.1.DenseReluDense.wi: 75497472
transformer.encoder.block.3.layer.1.DenseReluDense.wo: 75497472
transformer.encoder.block.3.layer.1.DenseReluDense.dropout: 0
transformer.encoder.block.3.layer.1.DenseReluDense.act: 0
transformer.encoder.block.3.layer.1.layer_norm: 0
transformer.encoder.block.3.layer.1.dropout: 0
transformer.encoder.block.4: 227278848
transformer.encoder.block.4.layer: 227278848
transformer.encoder.block.4.layer.0: 76283904
transformer.encoder.block.4.layer.0.SelfAttention: 76283904
transformer.encoder.block.4.layer.0.SelfAttention.q: 18874368
transformer.encoder.block.4.layer.0.SelfAttention.k: 18874368
transformer.encoder.block.4.layer.0.SelfAttention.v: 18874368
transformer.encoder.block.4.layer.0.SelfAttention.o: 18874368
transformer.encoder.block.4.layer.0.layer_norm: 0
transformer.encoder.block.4.layer.0.dropout: 0
transformer.encoder.block.4.layer.1: 150994944
transformer.encoder.block.4.layer.1.DenseReluDense: 150994944
transformer.encoder.block.4.layer.1.DenseReluDense.wi: 75497472
transformer.encoder.block.4.layer.1.DenseReluDense.wo: 75497472
transformer.encoder.block.4.layer.1.DenseReluDense.dropout: 0
transformer.encoder.block.4.layer.1.DenseReluDense.act: 0
transformer.encoder.block.4.layer.1.layer_norm: 0
transformer.encoder.block.4.layer.1.dropout: 0
transformer.encoder.block.5: 227278848
transformer.encoder.block.5.layer: 227278848
transformer.encoder.block.5.layer.0: 76283904
transformer.encoder.block.5.layer.0.SelfAttention: 76283904
transformer.encoder.block.5.layer.0.SelfAttention.q: 18874368
transformer.encoder.block.5.layer.0.SelfAttention.k: 18874368
transformer.encoder.block.5.layer.0.SelfAttention.v: 18874368
transformer.encoder.block.5.layer.0.SelfAttention.o: 18874368
transformer.encoder.block.5.layer.0.layer_norm: 0
transformer.encoder.block.5.layer.0.dropout: 0
transformer.encoder.block.5.layer.1: 150994944
transformer.encoder.block.5.layer.1.DenseReluDense: 150994944
transformer.encoder.block.5.layer.1.DenseReluDense.wi: 75497472
transformer.encoder.block.5.layer.1.DenseReluDense.wo: 75497472
transformer.encoder.block.5.layer.1.DenseReluDense.dropout: 0
transformer.encoder.block.5.layer.1.DenseReluDense.act: 0
transformer.encoder.block.5.layer.1.layer_norm: 0
transformer.encoder.block.5.layer.1.dropout: 0
transformer.encoder.block.6: 227278848
transformer.encoder.block.6.layer: 227278848
transformer.encoder.block.6.layer.0: 76283904
transformer.encoder.block.6.layer.0.SelfAttention: 76283904
transformer.encoder.block.6.layer.0.SelfAttention.q: 18874368
transformer.encoder.block.6.layer.0.SelfAttention.k: 18874368
transformer.encoder.block.6.layer.0.SelfAttention.v: 18874368
transformer.encoder.block.6.layer.0.SelfAttention.o: 18874368
transformer.encoder.block.6.layer.0.layer_norm: 0
transformer.encoder.block.6.layer.0.dropout: 0
transformer.encoder.block.6.layer.1: 150994944
transformer.encoder.block.6.layer.1.DenseReluDense: 150994944
transformer.encoder.block.6.layer.1.DenseReluDense.wi: 75497472
transformer.encoder.block.6.layer.1.DenseReluDense.wo: 75497472
transformer.encoder.block.6.layer.1.DenseReluDense.dropout: 0
transformer.encoder.block.6.layer.1.DenseReluDense.act: 0
transformer.encoder.block.6.layer.1.layer_norm: 0
transformer.encoder.block.6.layer.1.dropout: 0
transformer.encoder.block.7: 227278848
transformer.encoder.block.7.layer: 227278848
transformer.encoder.block.7.layer.0: 76283904
transformer.encoder.block.7.layer.0.SelfAttention: 76283904
transformer.encoder.block.7.layer.0.SelfAttention.q: 18874368
transformer.encoder.block.7.layer.0.SelfAttention.k: 18874368
transformer.encoder.block.7.layer.0.SelfAttention.v: 18874368
transformer.encoder.block.7.layer.0.SelfAttention.o: 18874368
transformer.encoder.block.7.layer.0.layer_norm: 0
transformer.encoder.block.7.layer.0.dropout: 0
transformer.encoder.block.7.layer.1: 150994944
transformer.encoder.block.7.layer.1.DenseReluDense: 150994944
transformer.encoder.block.7.layer.1.DenseReluDense.wi: 75497472
transformer.encoder.block.7.layer.1.DenseReluDense.wo: 75497472
transformer.encoder.block.7.layer.1.DenseReluDense.dropout: 0
transformer.encoder.block.7.layer.1.DenseReluDense.act: 0
transformer.encoder.block.7.layer.1.layer_norm: 0
transformer.encoder.block.7.layer.1.dropout: 0
transformer.encoder.block.8: 227278848
transformer.encoder.block.8.layer: 227278848
transformer.encoder.block.8.layer.0: 76283904
transformer.encoder.block.8.layer.0.SelfAttention: 76283904
transformer.encoder.block.8.layer.0.SelfAttention.q: 18874368
transformer.encoder.block.8.layer.0.SelfAttention.k: 18874368
transformer.encoder.block.8.layer.0.SelfAttention.v: 18874368
transformer.encoder.block.8.layer.0.SelfAttention.o: 18874368
transformer.encoder.block.8.layer.0.layer_norm: 0
transformer.encoder.block.8.layer.0.dropout: 0
transformer.encoder.block.8.layer.1: 150994944
transformer.encoder.block.8.layer.1.DenseReluDense: 150994944
transformer.encoder.block.8.layer.1.DenseReluDense.wi: 75497472
transformer.encoder.block.8.layer.1.DenseReluDense.wo: 75497472
transformer.encoder.block.8.layer.1.DenseReluDense.dropout: 0
transformer.encoder.block.8.layer.1.DenseReluDense.act: 0
transformer.encoder.block.8.layer.1.layer_norm: 0
transformer.encoder.block.8.layer.1.dropout: 0
transformer.encoder.block.9: 227278848
transformer.encoder.block.9.layer: 227278848
transformer.encoder.block.9.layer.0: 76283904
transformer.encoder.block.9.layer.0.SelfAttention: 76283904
transformer.encoder.block.9.layer.0.SelfAttention.q: 18874368
transformer.encoder.block.9.layer.0.SelfAttention.k: 18874368
transformer.encoder.block.9.layer.0.SelfAttention.v: 18874368
transformer.encoder.block.9.layer.0.SelfAttention.o: 18874368
transformer.encoder.block.9.layer.0.layer_norm: 0
transformer.encoder.block.9.layer.0.dropout: 0
transformer.encoder.block.9.layer.1: 150994944
transformer.encoder.block.9.layer.1.DenseReluDense: 150994944
transformer.encoder.block.9.layer.1.DenseReluDense.wi: 75497472
transformer.encoder.block.9.layer.1.DenseReluDense.wo: 75497472
transformer.encoder.block.9.layer.1.DenseReluDense.dropout: 0
transformer.encoder.block.9.layer.1.DenseReluDense.act: 0
transformer.encoder.block.9.layer.1.layer_norm: 0
transformer.encoder.block.9.layer.1.dropout: 0
transformer.encoder.block.10: 227278848
transformer.encoder.block.10.layer: 227278848
transformer.encoder.block.10.layer.0: 76283904
transformer.encoder.block.10.layer.0.SelfAttention: 76283904
transformer.encoder.block.10.layer.0.SelfAttention.q: 18874368
transformer.encoder.block.10.layer.0.SelfAttention.k: 18874368
transformer.encoder.block.10.layer.0.SelfAttention.v: 18874368
transformer.encoder.block.10.layer.0.SelfAttention.o: 18874368
transformer.encoder.block.10.layer.0.layer_norm: 0
transformer.encoder.block.10.layer.0.dropout: 0
transformer.encoder.block.10.layer.1: 150994944
transformer.encoder.block.10.layer.1.DenseReluDense: 150994944
transformer.encoder.block.10.layer.1.DenseReluDense.wi: 75497472
transformer.encoder.block.10.layer.1.DenseReluDense.wo: 75497472
transformer.encoder.block.10.layer.1.DenseReluDense.dropout: 0
transformer.encoder.block.10.layer.1.DenseReluDense.act: 0
transformer.encoder.block.10.layer.1.layer_norm: 0
transformer.encoder.block.10.layer.1.dropout: 0
transformer.encoder.block.11: 227278848
transformer.encoder.block.11.layer: 227278848
transformer.encoder.block.11.layer.0: 76283904
transformer.encoder.block.11.layer.0.SelfAttention: 76283904
transformer.encoder.block.11.layer.0.SelfAttention.q: 18874368
transformer.encoder.block.11.layer.0.SelfAttention.k: 18874368
transformer.encoder.block.11.layer.0.SelfAttention.v: 18874368
transformer.encoder.block.11.layer.0.SelfAttention.o: 18874368
transformer.encoder.block.11.layer.0.layer_norm: 0
transformer.encoder.block.11.layer.0.dropout: 0
transformer.encoder.block.11.layer.1: 150994944
transformer.encoder.block.11.layer.1.DenseReluDense: 150994944
transformer.encoder.block.11.layer.1.DenseReluDense.wi: 75497472
transformer.encoder.block.11.layer.1.DenseReluDense.wo: 75497472
transformer.encoder.block.11.layer.1.DenseReluDense.dropout: 0
transformer.encoder.block.11.layer.1.DenseReluDense.act: 0
transformer.encoder.block.11.layer.1.layer_norm: 0
transformer.encoder.block.11.layer.1.dropout: 0
transformer.encoder.final_layer_norm: 0
transformer.encoder.dropout: 0
transformer.decoder: 0
transformer.decoder.block: 0
transformer.decoder.block.0: 0
transformer.decoder.block.0.layer: 0
transformer.decoder.block.0.layer.0: 0
transformer.decoder.block.0.layer.0.SelfAttention: 0
transformer.decoder.block.0.layer.0.SelfAttention.q: 0
transformer.decoder.block.0.layer.0.SelfAttention.k: 0
transformer.decoder.block.0.layer.0.SelfAttention.v: 0
transformer.decoder.block.0.layer.0.SelfAttention.o: 0
transformer.decoder.block.0.layer.0.SelfAttention.relative_attention_bias: 0
transformer.decoder.block.0.layer.0.layer_norm: 0
transformer.decoder.block.0.layer.0.dropout: 0
transformer.decoder.block.0.layer.1: 0
transformer.decoder.block.0.layer.1.EncDecAttention: 0
transformer.decoder.block.0.layer.1.EncDecAttention.q: 0
transformer.decoder.block.0.layer.1.EncDecAttention.k: 0
transformer.decoder.block.0.layer.1.EncDecAttention.v: 0
transformer.decoder.block.0.layer.1.EncDecAttention.o: 0
transformer.decoder.block.0.layer.1.layer_norm: 0
transformer.decoder.block.0.layer.1.dropout: 0
transformer.decoder.block.0.layer.2: 0
transformer.decoder.block.0.layer.2.DenseReluDense: 0
transformer.decoder.block.0.layer.2.DenseReluDense.wi: 0
transformer.decoder.block.0.layer.2.DenseReluDense.wo: 0
transformer.decoder.block.0.layer.2.DenseReluDense.dropout: 0
transformer.decoder.block.0.layer.2.DenseReluDense.act: 0
transformer.decoder.block.0.layer.2.layer_norm: 0
transformer.decoder.block.0.layer.2.dropout: 0
transformer.decoder.block.1: 0
transformer.decoder.block.1.layer: 0
transformer.decoder.block.1.layer.0: 0
transformer.decoder.block.1.layer.0.SelfAttention: 0
transformer.decoder.block.1.layer.0.SelfAttention.q: 0
transformer.decoder.block.1.layer.0.SelfAttention.k: 0
transformer.decoder.block.1.layer.0.SelfAttention.v: 0
transformer.decoder.block.1.layer.0.SelfAttention.o: 0
transformer.decoder.block.1.layer.0.layer_norm: 0
transformer.decoder.block.1.layer.0.dropout: 0
transformer.decoder.block.1.layer.1: 0
transformer.decoder.block.1.layer.1.EncDecAttention: 0
transformer.decoder.block.1.layer.1.EncDecAttention.q: 0
transformer.decoder.block.1.layer.1.EncDecAttention.k: 0
transformer.decoder.block.1.layer.1.EncDecAttention.v: 0
transformer.decoder.block.1.layer.1.EncDecAttention.o: 0
transformer.decoder.block.1.layer.1.layer_norm: 0
transformer.decoder.block.1.layer.1.dropout: 0
transformer.decoder.block.1.layer.2: 0
transformer.decoder.block.1.layer.2.DenseReluDense: 0
transformer.decoder.block.1.layer.2.DenseReluDense.wi: 0
transformer.decoder.block.1.layer.2.DenseReluDense.wo: 0
transformer.decoder.block.1.layer.2.DenseReluDense.dropout: 0
transformer.decoder.block.1.layer.2.DenseReluDense.act: 0
transformer.decoder.block.1.layer.2.layer_norm: 0
transformer.decoder.block.1.layer.2.dropout: 0
transformer.decoder.block.2: 0
transformer.decoder.block.2.layer: 0
transformer.decoder.block.2.layer.0: 0
transformer.decoder.block.2.layer.0.SelfAttention: 0
transformer.decoder.block.2.layer.0.SelfAttention.q: 0
transformer.decoder.block.2.layer.0.SelfAttention.k: 0
transformer.decoder.block.2.layer.0.SelfAttention.v: 0
transformer.decoder.block.2.layer.0.SelfAttention.o: 0
transformer.decoder.block.2.layer.0.layer_norm: 0
transformer.decoder.block.2.layer.0.dropout: 0
transformer.decoder.block.2.layer.1: 0
transformer.decoder.block.2.layer.1.EncDecAttention: 0
transformer.decoder.block.2.layer.1.EncDecAttention.q: 0
transformer.decoder.block.2.layer.1.EncDecAttention.k: 0
transformer.decoder.block.2.layer.1.EncDecAttention.v: 0
transformer.decoder.block.2.layer.1.EncDecAttention.o: 0
transformer.decoder.block.2.layer.1.layer_norm: 0
transformer.decoder.block.2.layer.1.dropout: 0
transformer.decoder.block.2.layer.2: 0
transformer.decoder.block.2.layer.2.DenseReluDense: 0
transformer.decoder.block.2.layer.2.DenseReluDense.wi: 0
transformer.decoder.block.2.layer.2.DenseReluDense.wo: 0
transformer.decoder.block.2.layer.2.DenseReluDense.dropout: 0
transformer.decoder.block.2.layer.2.DenseReluDense.act: 0
transformer.decoder.block.2.layer.2.layer_norm: 0
transformer.decoder.block.2.layer.2.dropout: 0
transformer.decoder.block.3: 0
transformer.decoder.block.3.layer: 0
transformer.decoder.block.3.layer.0: 0
transformer.decoder.block.3.layer.0.SelfAttention: 0
transformer.decoder.block.3.layer.0.SelfAttention.q: 0
transformer.decoder.block.3.layer.0.SelfAttention.k: 0
transformer.decoder.block.3.layer.0.SelfAttention.v: 0
transformer.decoder.block.3.layer.0.SelfAttention.o: 0
transformer.decoder.block.3.layer.0.layer_norm: 0
transformer.decoder.block.3.layer.0.dropout: 0
transformer.decoder.block.3.layer.1: 0
transformer.decoder.block.3.layer.1.EncDecAttention: 0
transformer.decoder.block.3.layer.1.EncDecAttention.q: 0
transformer.decoder.block.3.layer.1.EncDecAttention.k: 0
transformer.decoder.block.3.layer.1.EncDecAttention.v: 0
transformer.decoder.block.3.layer.1.EncDecAttention.o: 0
transformer.decoder.block.3.layer.1.layer_norm: 0
transformer.decoder.block.3.layer.1.dropout: 0
transformer.decoder.block.3.layer.2: 0
transformer.decoder.block.3.layer.2.DenseReluDense: 0
transformer.decoder.block.3.layer.2.DenseReluDense.wi: 0
transformer.decoder.block.3.layer.2.DenseReluDense.wo: 0
transformer.decoder.block.3.layer.2.DenseReluDense.dropout: 0
transformer.decoder.block.3.layer.2.DenseReluDense.act: 0
transformer.decoder.block.3.layer.2.layer_norm: 0
transformer.decoder.block.3.layer.2.dropout: 0
transformer.decoder.block.4: 0
transformer.decoder.block.4.layer: 0
transformer.decoder.block.4.layer.0: 0
transformer.decoder.block.4.layer.0.SelfAttention: 0
transformer.decoder.block.4.layer.0.SelfAttention.q: 0
transformer.decoder.block.4.layer.0.SelfAttention.k: 0
transformer.decoder.block.4.layer.0.SelfAttention.v: 0
transformer.decoder.block.4.layer.0.SelfAttention.o: 0
transformer.decoder.block.4.layer.0.layer_norm: 0
transformer.decoder.block.4.layer.0.dropout: 0
transformer.decoder.block.4.layer.1: 0
transformer.decoder.block.4.layer.1.EncDecAttention: 0
transformer.decoder.block.4.layer.1.EncDecAttention.q: 0
transformer.decoder.block.4.layer.1.EncDecAttention.k: 0
transformer.decoder.block.4.layer.1.EncDecAttention.v: 0
transformer.decoder.block.4.layer.1.EncDecAttention.o: 0
transformer.decoder.block.4.layer.1.layer_norm: 0
transformer.decoder.block.4.layer.1.dropout: 0
transformer.decoder.block.4.layer.2: 0
transformer.decoder.block.4.layer.2.DenseReluDense: 0
transformer.decoder.block.4.layer.2.DenseReluDense.wi: 0
transformer.decoder.block.4.layer.2.DenseReluDense.wo: 0
transformer.decoder.block.4.layer.2.DenseReluDense.dropout: 0
transformer.decoder.block.4.layer.2.DenseReluDense.act: 0
transformer.decoder.block.4.layer.2.layer_norm: 0
transformer.decoder.block.4.layer.2.dropout: 0
transformer.decoder.block.5: 0
transformer.decoder.block.5.layer: 0
transformer.decoder.block.5.layer.0: 0
transformer.decoder.block.5.layer.0.SelfAttention: 0
transformer.decoder.block.5.layer.0.SelfAttention.q: 0
transformer.decoder.block.5.layer.0.SelfAttention.k: 0
transformer.decoder.block.5.layer.0.SelfAttention.v: 0
transformer.decoder.block.5.layer.0.SelfAttention.o: 0
transformer.decoder.block.5.layer.0.layer_norm: 0
transformer.decoder.block.5.layer.0.dropout: 0
transformer.decoder.block.5.layer.1: 0
transformer.decoder.block.5.layer.1.EncDecAttention: 0
transformer.decoder.block.5.layer.1.EncDecAttention.q: 0
transformer.decoder.block.5.layer.1.EncDecAttention.k: 0
transformer.decoder.block.5.layer.1.EncDecAttention.v: 0
transformer.decoder.block.5.layer.1.EncDecAttention.o: 0
transformer.decoder.block.5.layer.1.layer_norm: 0
transformer.decoder.block.5.layer.1.dropout: 0
transformer.decoder.block.5.layer.2: 0
transformer.decoder.block.5.layer.2.DenseReluDense: 0
transformer.decoder.block.5.layer.2.DenseReluDense.wi: 0
transformer.decoder.block.5.layer.2.DenseReluDense.wo: 0
transformer.decoder.block.5.layer.2.DenseReluDense.dropout: 0
transformer.decoder.block.5.layer.2.DenseReluDense.act: 0
transformer.decoder.block.5.layer.2.layer_norm: 0
transformer.decoder.block.5.layer.2.dropout: 0
transformer.decoder.block.6: 0
transformer.decoder.block.6.layer: 0
transformer.decoder.block.6.layer.0: 0
transformer.decoder.block.6.layer.0.SelfAttention: 0
transformer.decoder.block.6.layer.0.SelfAttention.q: 0
transformer.decoder.block.6.layer.0.SelfAttention.k: 0
transformer.decoder.block.6.layer.0.SelfAttention.v: 0
transformer.decoder.block.6.layer.0.SelfAttention.o: 0
transformer.decoder.block.6.layer.0.layer_norm: 0
transformer.decoder.block.6.layer.0.dropout: 0
transformer.decoder.block.6.layer.1: 0
transformer.decoder.block.6.layer.1.EncDecAttention: 0
transformer.decoder.block.6.layer.1.EncDecAttention.q: 0
transformer.decoder.block.6.layer.1.EncDecAttention.k: 0
transformer.decoder.block.6.layer.1.EncDecAttention.v: 0
transformer.decoder.block.6.layer.1.EncDecAttention.o: 0
transformer.decoder.block.6.layer.1.layer_norm: 0
transformer.decoder.block.6.layer.1.dropout: 0
transformer.decoder.block.6.layer.2: 0
transformer.decoder.block.6.layer.2.DenseReluDense: 0
transformer.decoder.block.6.layer.2.DenseReluDense.wi: 0
transformer.decoder.block.6.layer.2.DenseReluDense.wo: 0
transformer.decoder.block.6.layer.2.DenseReluDense.dropout: 0
transformer.decoder.block.6.layer.2.DenseReluDense.act: 0
transformer.decoder.block.6.layer.2.layer_norm: 0
transformer.decoder.block.6.layer.2.dropout: 0
transformer.decoder.block.7: 0
transformer.decoder.block.7.layer: 0
transformer.decoder.block.7.layer.0: 0
transformer.decoder.block.7.layer.0.SelfAttention: 0
transformer.decoder.block.7.layer.0.SelfAttention.q: 0
transformer.decoder.block.7.layer.0.SelfAttention.k: 0
transformer.decoder.block.7.layer.0.SelfAttention.v: 0
transformer.decoder.block.7.layer.0.SelfAttention.o: 0
transformer.decoder.block.7.layer.0.layer_norm: 0
transformer.decoder.block.7.layer.0.dropout: 0
transformer.decoder.block.7.layer.1: 0
transformer.decoder.block.7.layer.1.EncDecAttention: 0
transformer.decoder.block.7.layer.1.EncDecAttention.q: 0
transformer.decoder.block.7.layer.1.EncDecAttention.k: 0
transformer.decoder.block.7.layer.1.EncDecAttention.v: 0
transformer.decoder.block.7.layer.1.EncDecAttention.o: 0
transformer.decoder.block.7.layer.1.layer_norm: 0
transformer.decoder.block.7.layer.1.dropout: 0
transformer.decoder.block.7.layer.2: 0
transformer.decoder.block.7.layer.2.DenseReluDense: 0
transformer.decoder.block.7.layer.2.DenseReluDense.wi: 0
transformer.decoder.block.7.layer.2.DenseReluDense.wo: 0
transformer.decoder.block.7.layer.2.DenseReluDense.dropout: 0
transformer.decoder.block.7.layer.2.DenseReluDense.act: 0
transformer.decoder.block.7.layer.2.layer_norm: 0
transformer.decoder.block.7.layer.2.dropout: 0
transformer.decoder.block.8: 0
transformer.decoder.block.8.layer: 0
transformer.decoder.block.8.layer.0: 0
transformer.decoder.block.8.layer.0.SelfAttention: 0
transformer.decoder.block.8.layer.0.SelfAttention.q: 0
transformer.decoder.block.8.layer.0.SelfAttention.k: 0
transformer.decoder.block.8.layer.0.SelfAttention.v: 0
transformer.decoder.block.8.layer.0.SelfAttention.o: 0
transformer.decoder.block.8.layer.0.layer_norm: 0
transformer.decoder.block.8.layer.0.dropout: 0
transformer.decoder.block.8.layer.1: 0
transformer.decoder.block.8.layer.1.EncDecAttention: 0
transformer.decoder.block.8.layer.1.EncDecAttention.q: 0
transformer.decoder.block.8.layer.1.EncDecAttention.k: 0
transformer.decoder.block.8.layer.1.EncDecAttention.v: 0
transformer.decoder.block.8.layer.1.EncDecAttention.o: 0
transformer.decoder.block.8.layer.1.layer_norm: 0
transformer.decoder.block.8.layer.1.dropout: 0
transformer.decoder.block.8.layer.2: 0
transformer.decoder.block.8.layer.2.DenseReluDense: 0
transformer.decoder.block.8.layer.2.DenseReluDense.wi: 0
transformer.decoder.block.8.layer.2.DenseReluDense.wo: 0
transformer.decoder.block.8.layer.2.DenseReluDense.dropout: 0
transformer.decoder.block.8.layer.2.DenseReluDense.act: 0
transformer.decoder.block.8.layer.2.layer_norm: 0
transformer.decoder.block.8.layer.2.dropout: 0
transformer.decoder.block.9: 0
transformer.decoder.block.9.layer: 0
transformer.decoder.block.9.layer.0: 0
transformer.decoder.block.9.layer.0.SelfAttention: 0
transformer.decoder.block.9.layer.0.SelfAttention.q: 0
transformer.decoder.block.9.layer.0.SelfAttention.k: 0
transformer.decoder.block.9.layer.0.SelfAttention.v: 0
transformer.decoder.block.9.layer.0.SelfAttention.o: 0
transformer.decoder.block.9.layer.0.layer_norm: 0
transformer.decoder.block.9.layer.0.dropout: 0
transformer.decoder.block.9.layer.1: 0
transformer.decoder.block.9.layer.1.EncDecAttention: 0
transformer.decoder.block.9.layer.1.EncDecAttention.q: 0
transformer.decoder.block.9.layer.1.EncDecAttention.k: 0
transformer.decoder.block.9.layer.1.EncDecAttention.v: 0
transformer.decoder.block.9.layer.1.EncDecAttention.o: 0
transformer.decoder.block.9.layer.1.layer_norm: 0
transformer.decoder.block.9.layer.1.dropout: 0
transformer.decoder.block.9.layer.2: 0
transformer.decoder.block.9.layer.2.DenseReluDense: 0
transformer.decoder.block.9.layer.2.DenseReluDense.wi: 0
transformer.decoder.block.9.layer.2.DenseReluDense.wo: 0
transformer.decoder.block.9.layer.2.DenseReluDense.dropout: 0
transformer.decoder.block.9.layer.2.DenseReluDense.act: 0
transformer.decoder.block.9.layer.2.layer_norm: 0
transformer.decoder.block.9.layer.2.dropout: 0
transformer.decoder.block.10: 0
transformer.decoder.block.10.layer: 0
transformer.decoder.block.10.layer.0: 0
transformer.decoder.block.10.layer.0.SelfAttention: 0
transformer.decoder.block.10.layer.0.SelfAttention.q: 0
transformer.decoder.block.10.layer.0.SelfAttention.k: 0
transformer.decoder.block.10.layer.0.SelfAttention.v: 0
transformer.decoder.block.10.layer.0.SelfAttention.o: 0
transformer.decoder.block.10.layer.0.layer_norm: 0
transformer.decoder.block.10.layer.0.dropout: 0
transformer.decoder.block.10.layer.1: 0
transformer.decoder.block.10.layer.1.EncDecAttention: 0
transformer.decoder.block.10.layer.1.EncDecAttention.q: 0
transformer.decoder.block.10.layer.1.EncDecAttention.k: 0
transformer.decoder.block.10.layer.1.EncDecAttention.v: 0
transformer.decoder.block.10.layer.1.EncDecAttention.o: 0
transformer.decoder.block.10.layer.1.layer_norm: 0
transformer.decoder.block.10.layer.1.dropout: 0
transformer.decoder.block.10.layer.2: 0
transformer.decoder.block.10.layer.2.DenseReluDense: 0
transformer.decoder.block.10.layer.2.DenseReluDense.wi: 0
transformer.decoder.block.10.layer.2.DenseReluDense.wo: 0
transformer.decoder.block.10.layer.2.DenseReluDense.dropout: 0
transformer.decoder.block.10.layer.2.DenseReluDense.act: 0
transformer.decoder.block.10.layer.2.layer_norm: 0
transformer.decoder.block.10.layer.2.dropout: 0
transformer.decoder.block.11: 0
transformer.decoder.block.11.layer: 0
transformer.decoder.block.11.layer.0: 0
transformer.decoder.block.11.layer.0.SelfAttention: 0
transformer.decoder.block.11.layer.0.SelfAttention.q: 0
transformer.decoder.block.11.layer.0.SelfAttention.k: 0
transformer.decoder.block.11.layer.0.SelfAttention.v: 0
transformer.decoder.block.11.layer.0.SelfAttention.o: 0
transformer.decoder.block.11.layer.0.layer_norm: 0
transformer.decoder.block.11.layer.0.dropout: 0
transformer.decoder.block.11.layer.1: 0
transformer.decoder.block.11.layer.1.EncDecAttention: 0
transformer.decoder.block.11.layer.1.EncDecAttention.q: 0
transformer.decoder.block.11.layer.1.EncDecAttention.k: 0
transformer.decoder.block.11.layer.1.EncDecAttention.v: 0
transformer.decoder.block.11.layer.1.EncDecAttention.o: 0
transformer.decoder.block.11.layer.1.layer_norm: 0
transformer.decoder.block.11.layer.1.dropout: 0
transformer.decoder.block.11.layer.2: 0
transformer.decoder.block.11.layer.2.DenseReluDense: 0
transformer.decoder.block.11.layer.2.DenseReluDense.wi: 0
transformer.decoder.block.11.layer.2.DenseReluDense.wo: 0
transformer.decoder.block.11.layer.2.DenseReluDense.dropout: 0
transformer.decoder.block.11.layer.2.DenseReluDense.act: 0
transformer.decoder.block.11.layer.2.layer_norm: 0
transformer.decoder.block.11.layer.2.dropout: 0
transformer.decoder.final_layer_norm: 0
transformer.decoder.dropout: 0
fc: 2359296

Таблица параметров:
| name                                    | #elements or shape   |
|:----------------------------------------|:---------------------|
| model                                   | 0.2G                 |
|  transformer                            |  0.2G                |
|   transformer.shared                    |   24.7M              |
|    transformer.shared.weight            |    (32128, 768)      |
|   transformer.encoder                   |   85.0M              |
|    transformer.encoder.block            |    85.0M             |
|    transformer.encoder.final_layer_norm |    0.8K              |
|   transformer.decoder                   |   0.1G               |
|    transformer.decoder.block            |    0.1G              |
|    transformer.decoder.final_layer_norm |    0.8K              |
|  fc                                     |  73.8K               |
|   fc.weight                             |   (96, 768)          |
|   fc.bias                               |   (96,)              |

Process finished with exit code 0
