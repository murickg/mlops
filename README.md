# TensorRT, Triton

Экспорт модели в ONNX, работа с Nvidia Triton Inference Server, компиляция в TensorRT
